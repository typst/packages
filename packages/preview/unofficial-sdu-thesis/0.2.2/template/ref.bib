@incollection{bay_surf_2006,
  title = {{{SURF}}: {{Speeded Up Robust Features}}},
  shorttitle = {{{SURF}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2006},
  author = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
  date = {2006},
  volume = {3951},
  pages = {404--417},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11744023_32},
  url = {http://link.springer.com/10.1007/11744023_32},
  urldate = {2024-11-19},
  abstract = {In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.},
  isbn = {978-3-540-33832-1 978-3-540-33833-8},
  langid = {english},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Bay et al. - 2006 - SURF Speeded Up Robust Features.pdf}
}

@online{choi_pose2mesh_2021,
  title = {{{Pose2Mesh}}: {{Graph Convolutional Network}} for {{3D Human Pose}} and {{Mesh Recovery}} from a {{2D Human Pose}}},
  shorttitle = {{{Pose2Mesh}}},
  author = {Choi, Hongsuk and Moon, Gyeongsik and Lee, Kyoung Mu},
  date = {2021-04-27},
  eprint = {2008.09047},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2008.09047},
  url = {http://arxiv.org/abs/2008.09047},
  urldate = {2024-11-21},
  abstract = {Most of the recent deep learning-based 3D human pose and mesh estimation methods regress the pose and shape parameters of human mesh models, such as SMPL and MANO, from an input image. The first weakness of these methods is an appearance domain gap problem, due to different image appearance between train data from controlled environments, such as a laboratory, and test data from in-the-wild environments. The second weakness is that the estimation of the pose parameters is quite challenging owing to the representation issues of 3D rotations. To overcome the above weaknesses, we propose Pose2Mesh, a novel graph convolutional neural network (GraphCNN)-based system that estimates the 3D coordinates of human mesh vertices directly from the 2D human pose. The 2D human pose as input provides essential human body articulation information, while having a relatively homogeneous geometric property between the two domains. Also, the proposed system avoids the representation issues, while fully exploiting the mesh topology using a GraphCNN in a coarse-to-fine manner. We show that our Pose2Mesh outperforms the previous 3D human pose and mesh estimation methods on various benchmark datasets. For the codes, see https://github.com/hongsukchoi/Pose2Mesh\_RELEASE.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Choi et al. - 2021 - Pose2Mesh Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose.pdf;/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/2008.html}
}

@article{kim_realtime_2015,
  title = {Real-{{Time Human Pose Estimation}} and {{Gesture Recognition}} from {{Depth Images Using Superpixels}} and {{SVM Classifier}}},
  author = {Kim, Hanguen and Lee, Sangwon and Lee, Dongsung and Choi, Soonmin and Ju, Jinsun and Myung, Hyun},
  date = {2015-05-26},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {15},
  number = {6},
  pages = {12410--12427},
  issn = {1424-8220},
  doi = {10.3390/s150612410},
  url = {https://www.mdpi.com/1424-8220/15/6/12410},
  urldate = {2024-11-20},
  abstract = {In this paper, we present human pose estimation and gesture recognition algorithms that use only depth information. The proposed methods are designed to be operated with only a CPU (central processing unit), so that the algorithm can be operated on a low-cost platform, such as an embedded board. The human pose estimation method is based on an SVM (support vector machine) and superpixels without prior knowledge of a human body model. In the gesture recognition method, gestures are recognized from the pose information of a human body. To recognize gestures regardless of motion speed, the proposed method utilizes the keyframe extraction method. Gesture recognition is performed by comparing input keyframes with keyframes in registered gestures. The gesture yielding the smallest comparison error is chosen as a recognized gesture. To prevent recognition of gestures when a person performs a gesture that is not registered, we derive the maximum allowable comparison errors by comparing each registered gesture with the other gestures. We evaluated our method using a dataset that we generated. The experiment results show that our method performs fairly well and is applicable in real environments.},
  langid = {english},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Kim et al. - 2015 - Real-Time Human Pose Estimation and Gesture Recognition from Depth Images Using Superpixels and SVM.pdf}
}

@article{lee_groundmovingplatformbased_2016,
  title = {Ground-{{Moving-Platform-Based Human Tracking Using Visual SLAM}} and {{Constrained Multiple Kernels}}},
  author = {Lee, Kuan-Hui and Hwang, Jenq-Neng and Okopal, Greg and Pitton, James},
  date = {2016-12},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {17},
  number = {12},
  pages = {3602--3612},
  issn = {1558-0016},
  doi = {10.1109/TITS.2016.2557763},
  url = {https://ieeexplore.ieee.org/abstract/document/7471496},
  urldate = {2024-10-27},
  abstract = {This paper proposes a robust ground-moving-platform-based human tracking system, which effectively integrates visual simultaneous localization and mapping (V-SLAM), human detection, ground plane estimation, and kernel-based tracking techniques. The proposed system systematically detects humans from recorded video frames of a moving camera and tracks the humans in the V-SLAM-inferred 3-D space via a tracking-by-detection scheme. To efficiently associate the detected human frame by frame, we propose a novel human tracking framework, combining the constrained-multiple-kernel tracking and the estimated 3-D information (depth), to globally optimize the data association between consecutive frames. By taking advantage of the appearance model and 3-D information, the proposed system not only achieves high effectiveness but also well handles occlusion in the tracking. Experimental results show the favorable performance of the proposed system, which efficiently tracks humans in a camera equipped on a ground-moving platform such as a dash camera and an unmanned ground vehicle.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {SLAM,Visualization},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Lee et al. - 2016 - Ground-Moving-Platform-Based Human Tracking Using Visual SLAM and Constrained Multiple Kernels.pdf;/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/7471496.html}
}

@online{stumberg_dmvio_2022,
  title = {{{DM-VIO}}: {{Delayed Marginalization Visual-Inertial Odometry}}},
  shorttitle = {{{DM-VIO}}},
  author = {family=Stumberg, given=Lukas, prefix=von, useprefix=false and Cremers, Daniel},
  date = {2022-01-11},
  eprint = {2201.04114},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2201.04114},
  url = {http://arxiv.org/abs/2201.04114},
  urldate = {2024-10-31},
  abstract = {We present DM-VIO, a monocular visual-inertial odometry system based on two novel techniques called delayed marginalization and pose graph bundle adjustment. DM-VIO performs photometric bundle adjustment with a dynamic weight for visual residuals. We adopt marginalization, which is a popular strategy to keep the update time constrained, but it cannot easily be reversed, and linearization points of connected variables have to be fixed. To overcome this we propose delayed marginalization: The idea is to maintain a second factor graph, where marginalization is delayed. This allows us to later readvance this delayed graph, yielding an updated marginalization prior with new and consistent linearization points. In addition, delayed marginalization enables us to inject IMU information into already marginalized states. This is the foundation of the proposed pose graph bundle adjustment, which we use for IMU initialization. In contrast to prior works on IMU initialization, it is able to capture the full photometric uncertainty, improving the scale estimation. In order to cope with initially unobservable scale, we continue to optimize scale and gravity direction in the main system after IMU initialization is complete. We evaluate our system on the EuRoC, TUM-VI, and 4Seasons datasets, which comprise flying drone, large-scale handheld, and automotive scenarios. Thanks to the proposed IMU initialization, our system exceeds the state of the art in visual-inertial odometry, even outperforming stereo-inertial methods while using only a single camera and IMU. The code will be published at http://vision.in.tum.de/dm-vio},
  pubstate = {prepublished},
  keywords = {VIO},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Stumberg and Cremers - 2022 - DM-VIO Delayed Marginalization Visual-Inertial Odometry.pdf;/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/2201.html}
}

@inproceedings{toshev_deeppose_2014,
  title = {{{DeepPose}}: {{Human Pose Estimation}} via {{Deep Neural Networks}}},
  shorttitle = {{{DeepPose}}},
  booktitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Toshev, Alexander and Szegedy, Christian},
  date = {2014-06},
  pages = {1653--1660},
  publisher = {IEEE},
  location = {Columbus, OH, USA},
  doi = {10.1109/CVPR.2014.214},
  url = {https://ieeexplore.ieee.org/document/6909610},
  urldate = {2024-11-20},
  abstract = {We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-ofart or better performance on four academic benchmarks of diverse real-world images.},
  eventtitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4799-5118-5},
  langid = {english},
  file = {/Users/groove/Library/CloudStorage/GoogleDrive-groovewjh@gmail.com/My Drive/ZoteroBase/Toshev and Szegedy - 2014 - DeepPose Human Pose Estimation via Deep Neural Networks.pdf}
}
