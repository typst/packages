#import "@local/qooklet:0.1.0": *
#show: doc => conf(
  title: "Bellman Eqation",
  author: "ivaquero",
  header-cap: "Reinforcement Learning",
  footer-cap: "ivaquero",
  outline-on: false,
  doc,
)

= Bellman Eqation

#definition("Bellman Eqation")[

  ...

  $
    text(v_Ï€ (s), fill: #rgb("#ff0000"))
    &= ğ”¼[R_(t+1)|S_t = s] + Î³ ğ”¼[G_(t+1)|S_t = s], \
    &= âˆ‘_(a âˆˆ ğ’œ) Ï€(a|s) âˆ‘_(r âˆˆ â„›) p(r|s,a) +
    Î³ âˆ‘_(a âˆˆ ğ’œ) Ï€(a|s) âˆ‘_(s^â€² âˆˆ ğ’®) p(s^â€²|s,a) v_Ï€ (s^â€²) \
    &= âˆ‘_(a âˆˆ ğ’œ) Ï€(a|s) [âˆ‘_(r âˆˆ â„›) p(r|s,a) r +
      Î³ âˆ‘_(s^â€² âˆˆ ğ’®) p(s^â€²|s,a) text(v_Ï€ (s^â€²), fill: #rgb("#ff0000"))], âˆ€s âˆˆ ğ’®
  $ <bellman>
]

= Bellman Optimal Eqation

By Eq. @bellman,...

$
  v(s) &= max_(Ï€(s) âˆˆ âˆ(s)) âˆ‘_(a âˆˆ ğ’œ) Ï€(a|s)(âˆ‘_(r âˆˆ â„›) p(r|s, a) r + Î³ âˆ‘_(s^â€² âˆˆ ğ’®) p(s^â€²|s, a) v(s^â€²)), quad &âˆ€s âˆˆ ğ’® \
  &= max_(Ï€(s) âˆˆ âˆ(s)) âˆ‘_(a âˆˆ ğ’œ) Ï€(a|s) q(s, a), quad &âˆ€s âˆˆ ğ’®
$ <boe>
